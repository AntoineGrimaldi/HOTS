%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Laurent Perrinet at 2020-11-10 14:21:46 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{Berens12,
	abstract = {Orientation tuning has been a classic model for understanding single-neuron computation in the neocortex. However, little is known about how orientation can be read out from the activity of neural populations, in particular in alert animals. Our study is a first step toward that goal. We recorded from up to 20 well isolated single neurons in the primary visual cortex of alert macaques simultaneously and applied a simple, neurally plausible decoder to read out the population code. We focus on two questions: First, what are the time course and the timescale at which orientation can be read out from the population response? Second, how complex does the decoding mechanism in a downstream neuron have to be to reliably discriminate between visual stimuli with different orientations? We show that the neural ensembles in primary visual cortex of awake macaques represent orientation in a way that facilitates a fast and simple readout mechanism: With an average latency of 30--80 ms, the population code can be read out instantaneously with a short integration time of only tens of milliseconds, and neither stimulus contrast nor correlations need to be taken into account to compute the optimal synaptic weight pattern. Our study shows that---similar to the case of single-neuron computation---the representation of orientation in the spike patterns of neural populations can serve as an exemplary case for understanding the computations performed by neural ensembles underlying visual processing during behavior.},
	author = {Berens, Philipp and Ecker, Alexander S. and Cotton, R. James and Ma, Wei Ji and Bethge, Matthias and Tolias, Andreas S.},
	date-added = {2020-11-09 16:59:28 +0100},
	date-modified = {2020-11-10 14:21:46 +0100},
	doi = {10.1523/JNEUROSCI.1335-12.2012},
	journal = {J Neur},
	number = {31},
	title = {A fast and simple population code for orientation in primate {{V1}}},
	url = {https://www.jneurosci.org/content/32/31/10618},
	volume = {32},
	year = {2012},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/32/31/10618},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1335-12.2012}}

@article{Lagorce17,
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B.},
	date-added = {2020-11-09 16:16:25 +0100},
	date-modified = {2020-11-09 16:16:25 +0100},
	doi = {10.1109/TPAMI.2016.2574707},
	file = {Attachment:/Users/laurentperrinet/Zotero/storage/EH96DS22/Lagorce et al. - 2017 - HOTS A Hierarchy of Event-Based Time-Surfaces for Pattern Recognition(4).pdf:application/pdf},
	issn = {0162-8828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {event-based vision, feature extraction, Neuromorphic sensing},
	number = {7},
	pages = {1346--1359},
	pmid = {27411216},
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216 http://ieeexplore.ieee.org/document/7508476/},
	volume = {39},
	year = {2017},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	Bdsk-Url-2 = {https://doi.org/10.1109/TPAMI.2016.2574707}}

@article{falanga2020dynamic,
	author = {Falanga, Davide and Kleber, Kevin and Scaramuzza, Davide},
	doi = {10.1126/scirobotics.aaz9712},
	journal = {Science Robotics},
	number = {40},
	publisher = {Science Robotics},
	title = {Dynamic obstacle avoidance for quadrotors with event cameras},
	volume = {5},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1126/scirobotics.aaz9712}}

@article{akolkar2015can,
	author = {Akolkar, Himanshu and Meyer, Cedric and Clady, Xavier and Marre, Olivier and Bartolozzi, Chiara and Panzeri, Stefano and Benosman, Ryad},
	doi = {doi:10.1162/NECO_a_00703},
	journal = {Neural computation},
	number = {3},
	pages = {561--593},
	publisher = {MIT Press},
	title = {What can neuromorphic event-driven precise timing add to spike-based pattern recognition?},
	volume = {27},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1162/NECO_a_00703}}

@article{BoutinFranciosiniChavaneRuffierPerrinet19,
	abstract = {Both neurophysiological and psychophysical experiments have pointed out the crucial role of recurrent and feedback connections to process context-dependent information in the early visual cortex. While numerous models have accounted for feedback effects at either neural or representational level, none of them were able to bind those two levels of analysis. Is it possible to describe feedback effects at both levels using the same model? We answer this question by combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical and convolutional framework. In this Sparse Deep Predictive Coding (SDPC) model, the SC component models the internal recurrent processing within each layer, and the PC component describes the interactions between layers using feedforward and feedback connections. Here, we train a 2-layered SDPC on two different databases of images, and we interpret it as a model of the early visual system (V1~&~V2). We first demonstrate that once the training has converged, SDPC exhibits oriented and localized receptive fields in V1 and more complex features in V2. Second, we analyze the effects of feedback on the neural organization beyond the classical receptive field of V1 neurons using interaction maps. These maps are similar to association fields and reflect the Gestalt principle of good continuation. We demonstrate that feedback signals reorganize interaction maps and modulate neural activity to promote contour integration. Third, we demonstrate at the representational level that the SDPC feedback connections are able to overcome noise in input images. Therefore, the SDPC captures the association field principle at the neural level which results in better disambiguation of blurred images at the representational level.},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Fr{\'e}d{\'e}ric Y and Ruffier, Franck and Perrinet, Laurent U},
	date = {2020-03-20},
	date-added = {2020-02-19 15:27:32 +0100},
	date-modified = {2020-02-19 15:27:32 +0100},
	grants = {doc-2-amu,phd-icn; mesocentre},
	journal = {Submitted},
	keywords = {sparse coding},
	preprint = {https://arxiv.org/abs/1902.07651},
	title = {Sparse Deep Predictive Coding captures contour integration capabilities of the early visual system},
	url = {https://arxiv.org/abs/1902.07651},
	year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/abs/1902.07651}}

@article{BoutinFranciosiniRuffierPerrinet20feedback,
	abstract = {Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images. The simplest solution to solve this computationally hard problem is to decompose it into independent layer-wise subproblems. However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers. In this study, a new model called 2-Layers Sparse Predictive Coding (2L-SPC) is introduced to assess the impact of this inter-layer feedback connection. In particular, the 2L-SPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of independent Lasso layers. The 2L-SPC and the 2-layers Hi-La networks are trained on 4 different databases and with different sparsity parameters on each layer. First, we show that the overall prediction error generated by 2L-SPC is lower thanks to the feedback mechanism as it transfers prediction error between layers. Second, we demonstrate that the inference stage of the 2L-SPC is faster to converge than for the Hi-La model. Third, we show that the 2L-SPC also accelerates the learning process. Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the 2L-SPC features are more generic and informative.},
	annote = {https://arxiv.org/abs/2002.00892},
	author = {Boutin, Victor and Franciosini, Angelo and Ruffier, Franck and Perrinet, Laurent U},
	date = {2020-02-04},
	date-added = {2020-02-19 15:27:32 +0100},
	date-modified = {2020-02-19 15:27:32 +0100},
	grants = {doc-2-amu,phd-icn; mesocentre},
	journal = {Submitted},
	keywords = {Deep Learning,sparse coding},
	preprint = {https://arxiv.org/abs/2002.00892},
	title = {Effect of top-down connections in Hierarchical Sparse Coding},
	url = {https://arxiv.org/abs/2002.00892},
	year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/abs/2002.00892}}

@article{putney2019precise,
	author = {Putney, Joy and Conn, Rachel and Sponberg, Simon},
	doi = {10.1101/602961},
	journal = {bioRxiv},
	pages = {602961},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Precise timing is ubiquitous, consistent and coordinated across a comprehensive, spike-resolved flight motor program},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1101/602961}}

@article{Taylor2007,
	author = {Taylor, GK and Krapp, HG},
	doi = {10.1016/S0065-2806(07)34005-8},
	journal = {Advances in insect physiology: Pnsect mechanics and control},
	pages = {231--316},
	title = {Sensory systems and flight stability: What do insects measure and why?},
	volume = {34},
	year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1016/S0065-2806(07)34005-8}}

@article{falanga2019fast,
	author = {Falanga, Davide and Kim, Suseong and Scaramuzza, Davide},
	journal = {IEEE Robotics and Automation Letters},
	number = {2},
	pages = {1884--1891},
	publisher = {IEEE},
	title = {How Fast Is Too Fast? The Role of Perception Latency in High-Speed Sense and Avoid},
	url = {http://rpg.ifi.uzh.ch/docs/RAL19_Falanga.pdf},
	volume = {4},
	year = {2019},
	Bdsk-Url-1 = {http://rpg.ifi.uzh.ch/docs/RAL19_Falanga.pdf}}

@article{Falanga19,
	abstract = {The recent advances in state estimation, perception, and navigation algorithms have significantly contributed to the ubiquitous use of quadrotors for inspection, mapping, and aerial imaging. To further increase the versatility of quadrotors, recent works investigated the use of an adaptive morphology, which consists of modifying the shape of the vehicle during flight to suit a specific task or environment. However, these works either increase the complexity of the platform or decrease its controllability. In this letter, we propose a novel, simpler, yet effective morphing design for quadrotors consisting of a frame with four independently rotating arms that fold around the main frame. To guarantee stable flight at all times, we exploit an optimal control strategy that adapts on the fly to the drone morphology. We demonstrate the versatility of the proposed adaptive morphology in different tasks, such as negotiation of narrow gaps, close inspection of vertical surfaces, and object grasping and transportation. The experiments are performed on an actual, fully autonomous quadrotor relying solely on onboard visual-inertial sensors and compute. No external motion tracking systems and computers are used. This is the first work showing stable flight without requiring any symmetry of the morphology.},
	author = {Falanga, Davide and Kleber, Kevin and Mintchev, Stefano and Floreano, Dario and Scaramuzza, Davide},
	date = {2019-04},
	doi = {10.1109/LRA.2018.2885575},
	file = {/Users/laurentperrinet/Zotero/storage/TIYKDYAP/8567932.html},
	issn = {2377-3766, 2377-3774},
	journaltitle = {IEEE Robotics and Automation Letters},
	keywords = {adaptive morphology,aerial imaging,Aerial systems: Applications,aerial systems: mechanics and control,autonomous aerial vehicles,controllability,drone morphology,Drones,foldable drone,fully autonomous quadrotor,helicopters,independently rotating arms,inspection,Inspection,mobile robots,morphing design,morphing quadrotor,Morphology,motion control,navigation algorithms,onboard visual-inertial sensors,optimal control,optimal control strategy,Propellers,quadrotors,Robots,robust/adaptive control of robotic systems,Shape,stable flight,state estimation,Task analysis},
	number = {2},
	pages = {209-216},
	shorttitle = {The {{Foldable Drone}}},
	title = {The {{Foldable Drone}}: {{A Morphing Quadrotor That Can Squeeze}} and {{Fly}}},
	volume = {4},
	Bdsk-Url-1 = {https://doi.org/10.1109/LRA.2018.2885575}}

@article{Clady14,
	author = {Clady, Xavier and Clercq, Charles and Ieng, Sio-Hoi and Houseini, Fouzhan and Randazzo, Marco and Natale, Lorenzo and Bartolozzi, Chiara and Benosman, Ryad},
	date-modified = {2020-11-09 16:14:25 +0100},
	journal = {Frontiers in neuroscience},
	publisher = {Frontiers Media SA},
	title = {Asynchronous visual event-driven time-to-contact},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2014.00009},
	volume = {8},
	year = {2014},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2014.00009}}

@article{Benosman14,
	abstract = {This paper introduces a new methodology to compute dense visual flow using the precise timings of spikes from an asynchronous event-driven retina. Biological retinas, and their artificial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual flow from the local properties of events' spatiotemporal space. We will show that precise visual flow orientation and amplitude can be estimated using a local differential approach on the surface defined by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-driven acquisition that allows the computation of motion flow with microsecond accuracy and at very low computational cost.},
	author = {Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and Ieng, Sio-Hoi and Bartolozzi, Chiara},
	date = {2014-02},
	doi = {10.1109/TNNLS.2013.2273537},
	file = {/Users/laurentperrinet/Zotero/storage/IZIEKDES/6589170.html},
	issn = {2162-237X, 2162-2388},
	journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {Algorithms,Artificial Intelligence,asynchronous event-driven retina,biological retinas,Cameras,Event-driven vision,Event-driven visual flow,Event-driven visual motion flow,eye,frame-grabber technologies,Humans,image sequences,local differential approach,Models; Neurological,Motion,neuromorphic sensors,Optic Flow,precise timings,precise visual flow orientation,real time,Real-time systems,Retina,Sensors,Timing,Visual Pathways,Visualization,Voltage control},
	number = {2},
	pages = {407-417},
	title = {Event-{{Based}} Visual Flow},
	volume = {25},
	Bdsk-Url-1 = {https://doi.org/10.1109/TNNLS.2013.2273537}}

@article{Riviere18,
	abstract = {Abstract The aerial robot presented here for the first time was based on a quadrotor structure, which is capable of unique morphing performances based on an actuated elastic mechanism. Like birds, which are able to negotiate narrow apertures despite their relatively large wingspan, our Quad-Morphing robot was able to pass through a narrow gap at a high forward speed of 2.5 m.s? 1 by swiftly folding up the structure supporting its propellers. A control strategy was developed to deal with the loss of controllability on the roll axis resulting from the folding process, while keeping the robot stable until it has crossed the gap. In addition, a complete recovery procedure was also implemented to stabilize the robot after the unfolding process. A new metric was also used to quantify the gain in terms of the gap-crossing ability in comparison with that observed with classical quadrotors with rigid bodies. The performances of these morphing robots are presented, and experiments performed with a real flying robot passing through a small aperture by reducing its wingspan by 48\% are described and discussed.},
	author = {Riviere, Valentin and Manecy, Augustin and Viollet, St{\'e}phane},
	date = {2018-05-30},
	doi = {10.1089/soro.2017.0120},
	issn = {2169-5172},
	journaltitle = {Soft Robotics},
	number = {5},
	pages = {541-553},
	shortjournal = {Soft Robotics},
	title = {Agile {{Robotic Fliers}}: {{A Morphing}}-{{Based Approach}}},
	volume = {5},
	Bdsk-Url-1 = {https://doi.org/10.1089/soro.2017.0120}}

@article{DupeyrouxBoutinSerresPerrinetViollet18,
	abstract = {This paper presents for the first time the embedded stand-alone version of the bio-inspired M2APix (Michaelis-Menten auto-adaptive pixels) sensor as a ventral optic flow sensor to endow glider-type unmanned aerial vehicles with autonomous landing ability. Assuming the aircraft is equipped with any reliable speed measurement system such as a global positioning system or an inertial measurement unit, we can use the velocity of the glider to determine with high precision its height while landing. This information is robust to different outdoor lighting conditions and over different kinds of textured ground, a crucial property to control the landing phase of the aircraft.},
	author = {Dupeyroux, Julien and Boutin, Victor and Serres, Julien R and Perrinet, Laurent and Viollet, St{\'e}phane},
	date = {2018},
	date-modified = {2019-02-25 23:21:16 +0100},
	doi = {10.1109/ISCAS.2018.8351433},
	grants = {doc-2-amu},
	journal = {ISCAS2018, IEEE International Symposium on Circuits and Systems},
	keywords = {Biologically Inspired Computer vision},
	preprint = {https://hal-amu.archives-ouvertes.fr/hal-01899440},
	title = {M2APix: a bio-inspired auto-adaptive visual sensor for robust ground height estimation},
	year = {2018},
	Bdsk-Url-1 = {https://ieeexplore.ieee.org/abstract/document/8351433}}

@article{Watson14,
	author = {Watson, Andrew B},
	journal = {Journal of vision},
	number = {7},
	pages = {15--15},
	publisher = {The Association for Research in Vision and Ophthalmology},
	title = {A formula for human retinal ganglion cell receptive field density as a function of visual field location},
	volume = {14},
	year = {2014}}
