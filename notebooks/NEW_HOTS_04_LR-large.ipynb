{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from mix_Network import *\n",
    "\n",
    "dataset = 'nmnist'\n",
    "records_path = '../Records/'\n",
    "timestr = datetime.datetime.now().date().isoformat()\n",
    "#timestr = '2020-11-25'\n",
    "algo = 'lagorce'\n",
    "\n",
    "ds = 10\n",
    "#ds = 75\n",
    "\n",
    "NbTrainingData = 7500//ds\n",
    "NbTestingData = 2500//ds\n",
    "\n",
    "tau = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmnist(NbTrainingData, NbTestingData):\n",
    "    class eventV(object):\n",
    "            def __init__(self, nbevt):\n",
    "                self.time = np.zeros((nbevt))\n",
    "                self.address = np.zeros((nbevt, 2))\n",
    "                self.polarity = np.zeros((nbevt))\n",
    "                self.ImageSize = [34,34]\n",
    "                self.ListPolarities = [0,1]\n",
    "                \n",
    "    learningset = tonic.datasets.NMNIST(save_to='../Data/',\n",
    "                                train=False,\n",
    "                                transform=None)\n",
    "    loader = tonic.datasets.DataLoader(learningset, shuffle=True)\n",
    "    \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTrainingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_train = eventV(nbtot)\n",
    "    labels_train = []\n",
    "    idx = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_train.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_train.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_train.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_train.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_train.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "            \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTestingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTestingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_test = eventV(nbtot)\n",
    "    labels_test = []\n",
    "    idx = 0\n",
    "    for i in range(NbTestingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_test.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_test.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_test.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_test.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_test.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "    events_cluster = []\n",
    "    return [events_train, events_test, events_cluster, labels_train, labels_test]\n",
    "\n",
    "# ### Building matrix for logistic regression\n",
    "def gather_data(events_in, labels_in,\n",
    "                tau_cla=.150, # characteristic time of a digit\n",
    "                sample_events=50, sample_space = 1,\n",
    "                verbose=False, debug=False):\n",
    "\n",
    "    n_events = events_in.time.shape[0]\n",
    "\n",
    "    c_int = lambda n, d : ((n - 1) // d) + 1\n",
    "    data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data\n",
    "\n",
    "    X = np.zeros((c_int(n_events, sample_events), len(data.ravel())))\n",
    "    y = np.zeros((c_int(n_events, sample_events), ))\n",
    "\n",
    "    for i_event in range(1, n_events):\n",
    "        if events_in.time[i_event]<events_in.time[i_event-1]:\n",
    "            data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data \n",
    "\n",
    "\n",
    "        data *= np.exp(-(events_in.time[i_event]-events_in.time[i_event-1])/tau_cla)\n",
    "        x_pos = events_in.address[i_event, 0]//sample_space\n",
    "        y_pos = events_in.address[i_event, 1]//sample_space\n",
    "        p = events_in.polarity[i_event]\n",
    "        data[int(x_pos), int(y_pos), int(p)] = 1.\n",
    "\n",
    "        if i_event % sample_events == sample_events//2 :\n",
    "            if debug:\n",
    "                print(f'DEBUG {i_event} {i_event//sample_events} ')\n",
    "                print(f'DEBUG {y[i_event//sample_events]}   ')\n",
    "                print(f'DEBUG  {labels_in[i_event]} ')\n",
    "            X[i_event//sample_events, :] = data.ravel()\n",
    "            y[i_event//sample_events] = labels_in[i_event]\n",
    "            \n",
    "    if verbose: print('Number of events: ' + str(X.shape[0])+' - Number of features: ' + str(X.shape[1]))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = False\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train = hots.training(loader, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test = hots.training(loader, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train, out_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train_hom = hots.training(loader, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test_hom = hots.training(loader, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train_hom, out_test_hom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train_hom, out_test_hom = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing logistic regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "# \n",
    "opts_LR = dict(max_iter=2000, # random_state=0,\n",
    "               n_jobs=-1, class_weight='balanced')\n",
    "#opts_LR['Cs'] = 5\n",
    "opts_LR['Cs'] = 32\n",
    "# TODO for a publication use 100 from 10^{-10} to 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tic():\n",
    "    global ttic\n",
    "    ttic = time.time()\n",
    "def toc():\n",
    "    print(f'Done in {time.time() - ttic:.3f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on raw input spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "dataset = get_nmnist(NbTrainingData, NbTestingData)\n",
    "events_train, events_test, events_cluster, labels_train, labels_test = dataset\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "X_train, y_train = gather_data(events_train, labels_train, verbose=verbose)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "lr = LR(**opts_LR).fit(X_train, y_train)\n",
    "print(f'Classification score for raw input is {lr.score(X_train, y_train):.3f} (train)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "X_test, y_test = gather_data(events_test, labels_test, verbose=verbose)\n",
    "print(f'Classification score for raw input is {lr.score(X_test, y_test):.3f} (test)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression with or without homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homeo in [True, False]:\n",
    "    print(40*'-')\n",
    "    print(f'homeo={homeo}')\n",
    "    print(40*'-')\n",
    "    if homeo:\n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train_hom[0], out_test_hom[0], out_train_hom[1], out_test_hom[1]\n",
    "    else: \n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train[0], out_test[0], out_train[1], out_test[1]\n",
    "        \n",
    "    X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "    lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "    \n",
    "    X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression with different solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'{homeo=}')\n",
    "    print(40*'-')\n",
    "    for solver, penalty in zip(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], ['l2', 'l2', 'l1', 'l2', 'l1']):\n",
    "        events_train_o, events_test_o, labels_train, labels_test = get_events(timestr, tau=tau, homeo=homeo, verbose=verbose)\n",
    "\n",
    "        tic = time.time()\n",
    "        X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "        lr = LR(solver=solver, penalty=penalty, verbose=verbose, **opts_LR).fit(X_train, y_train)\n",
    "        print(f'Classification score for {homeo=} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "        print(f'Fit done in {time.time() -tic:.3f} seconds for {solver=}')\n",
    "        X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "        print(f'Classification score for {homeo=} / {solver=} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'{homeo=}')\n",
    "    print(40*'-')\n",
    "    events_train_o, events_test_o, labels_train, labels_test = get_events(timestr, tau=tau, homeo=homeo, verbose=verbose)\n",
    "\n",
    "    for tau_cla in .15 * np.logspace(-1, 1, 7, base=4):\n",
    "\n",
    "        X_train, y_train = gather_data(events_train_o, labels_train, tau_cla=tau_cla, verbose=verbose)\n",
    "        lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "        print(f'Classification score for {tau_cla=:.3f} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "        X_test, y_test = gather_data(events_test_o, labels_test, tau_cla=tau_cla, verbose=verbose)\n",
    "        print(f'Classification score for {tau_cla=:.3f} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'{homeo=}')\n",
    "    print(40*'-')\n",
    "    events_train_o, events_test_o, labels_train, labels_test = get_events(timestr, tau=tau, homeo=homeo, verbose=verbose)\n",
    "\n",
    "    for sample_space in [4, 2, 1]:\n",
    "        X_train, y_train = gather_data(events_train_o, labels_train, sample_space=sample_space, verbose=verbose)\n",
    "        lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "        print(f'Classification score for {sample_space=} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "        X_test, y_test = gather_data(events_test_o, labels_test, sample_space=sample_space, verbose=verbose)\n",
    "        print(f'Classification score for {sample_space=} is {lr.score(X_test, y_test):.3f} (test)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauz = np.array([1e-5, 1e-4, 2e-4 ,3e-4, 4e-4, 5e-4, 6e-4, 7e-4,\n",
    "                 8e-4, 9e-4, 1e-3, 2e-3, 2.5e-3, 3e-3, 4e-3, 5e-3, \n",
    "                 1e-2, 2e-2])\n",
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'{homeo=}')\n",
    "    print(40*'-')\n",
    "    for tau_ in tauz:\n",
    "        events_train_o, events_test_o, labels_train, labels_test = get_events(timestr, tau=tau_, homeo=homeo, verbose=verbose)\n",
    "        \n",
    "        X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "        lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "        print(f'Classification score for {homeo=} & {tau_=:.6f} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "        X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "        print(f'Classification score for {homeo=} & {tau_=:.6f} is {lr.score(X_test, y_test):.3f} (test)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hots",
   "language": "python",
   "name": "hots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
