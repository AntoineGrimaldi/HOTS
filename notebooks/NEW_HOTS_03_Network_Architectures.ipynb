{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW HOTS 03 - Testing different architectures on N-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laurentperrinet/quantic/science/HomeHots/HOTS_clone_laurent/HOTS\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from mix_Network import *\n",
    "dataset = 'nmnist'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hots with homeostasis (best results of nbk NEW HOTS 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/sh/tg2ljlbmtzygrag/AADSKgJ2CjaBWh75HnTNZyhca/Test.zip?dl=1 to ../Data/nmnist_test.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c1872035e34a95aa613f0487bf2726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-55871bc57f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Records/EXP_03_NMNIST/2020-12-03-mix_hots_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhotshom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkrnlinit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomeo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloaderhom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotshom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning1by1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrainmaphom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaderhom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotshom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaderhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtestmaphom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaderhom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotshom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaderhom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainmaphom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/quantic/science/HomeHots/HOTS_clone_laurent/HOTS/mix_Network.py\u001b[0m in \u001b[0;36mlearning1by1\u001b[0;34m(self, nb_digit, dataset, diginit, filtering)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nmnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             learningset = tonic.datasets.NMNIST(save_to='../Data/',\n\u001b[0m\u001b[1;32m     64\u001b[0m                                 \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                 transform=None)\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tonic/datasets/nmnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, save_to, train, download, transform, target_transform, first_saccade_only)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         if not check_integrity(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tonic/datasets/nmnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         download_and_extract_archive(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_on_system\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_md5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# check integrity of downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found or corrupted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "tau = 1\n",
    "homeo = True\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_03_NMNIST/2020-12-03-mix_hots_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learning1by1(dataset=dataset)\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "        \n",
    "hotshom.plotlayer()\n",
    "print('bhatta -> ',accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Testing different tauz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "for tau in [0.1, 0.5, 1, 2, 5, 10]:\n",
    "    hotshom = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "    arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "    fname = \"../Records/EXP_03_NMNIST/2020-12-03-mix_hots_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "    print(fname)\n",
    "    if not os.path.isfile(fname):\n",
    "        loaderhom = hotshom.learning1by1()\n",
    "        trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "        testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "        with open(fname, 'wb') as file:\n",
    "            pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname, 'rb') as file:\n",
    "            hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "        print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Testing different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "tau = 5\n",
    "for nblayerz in [1, 2, 3]:\n",
    "    for nbclust in [4, 8, 16]:\n",
    "        hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust)\n",
    "        arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "        fname = \"../Records/EXP_03_NMNIST/2020-12-03-mix_hots_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "        print(fname)\n",
    "        if not os.path.isfile(fname):\n",
    "            loaderhom = hotshom.learning1by1()\n",
    "            trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "            testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "            with open(fname, 'wb') as file:\n",
    "                pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "        else:\n",
    "            with open(fname, 'rb') as file:\n",
    "                hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "            print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filtering all TS on the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "tau = 5\n",
    "nblayerz = 3\n",
    "nbclust =4\n",
    "\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_03_NMNIST/2020-12-03-mix_hots_filtall_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "print(fname)\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learning1by1(filtering='all')\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "    print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stronger filter on the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "tau = 5\n",
    "nblayerz = 3\n",
    "nbclust =4\n",
    "\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust, filt=5)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_filtallx5_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "print(fname)\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learning1by1(filtering='all')\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "    print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No homeostasis on the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = False\n",
    "tau = 5\n",
    "nblayerz = 3\n",
    "nbclust =4\n",
    "\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "print(fname)\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learning1by1()\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "    print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training all layers at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = False\n",
    "tau = 5\n",
    "nblayerz = 3\n",
    "nbclust =4\n",
    "\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_learnall_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "print(fname)\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learningall()\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "    print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "tau = 5\n",
    "nblayerz = 3\n",
    "nbclust =4\n",
    "\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo, nblay=nblayerz, nbclust= nbclust)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_learnall_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "print(fname)\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learningall()\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "    print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "for tau in [0.1, 0.5, 1, 2, 5, 10, 20]:\n",
    "    hotshom = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "    arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "    fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_learnall_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "    print(fname)\n",
    "    if not os.path.isfile(fname):\n",
    "        loaderhom = hotshom.learningall()\n",
    "        trainmaphom, loaderhom, _ = hotshom.training(loaderhom)\n",
    "        testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "        with open(fname, 'wb') as file:\n",
    "            pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname, 'rb') as file:\n",
    "            hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "        print(accuracy(trainmaphom, testmaphom, 'bhatta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training on more videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 5\n",
    "homeo = True\n",
    "hotshom = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "fname = \"../Records/EXP_01_LagorceKmeans/2020-12-03-mix_hots_200_\"+dataset+hotshom.L[-1].krnlinit+str(tau)+str(homeo)+str(arch)+'.pkl'\n",
    "if not os.path.isfile(fname):\n",
    "    loaderhom = hotshom.learning1by1()\n",
    "    trainmaphom, loaderhom, _ = hotshom.training(loaderhom, nb_digit = 200)\n",
    "    testmaphom, loaderhom, _ = hotshom.testing(loaderhom, trainmaphom)\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump([hotshom, trainmaphom, testmaphom], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname, 'rb') as file:\n",
    "        hotshom, trainmaphom, testmaphom = pickle.load(file)\n",
    "hotshom.plotlayer()\n",
    "accuracy(trainmaphom, testmaphom, 'bhatta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hots",
   "language": "python",
   "name": "hots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
