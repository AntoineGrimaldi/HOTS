{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laurentperrinet/quantic/science/HomeHots/HOTS_clone_laurent\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 7, 8, 0, 4, 9, 2, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "from HOTS.ToolsMonitor import GenerateActivationMap, DisplayActivationMap\n",
    "from HOTS.Event import Event, SimpleAlphabet, LoadNMNIST\n",
    "from HOTS.STS import STS\n",
    "from HOTS.Layer import ClusteringLayer\n",
    "from HOTS.ToolsMonitor import (\n",
    "    DisplayImage,\n",
    "    DisplaySurface3D,\n",
    "    DisplaySurface2D,\n",
    "    DisplayConvergence,\n",
    ")\n",
    "from HOTS.Tools import SaveObject, LoadObject\n",
    "from HOTS.Classifier import Classifier\n",
    "from HOTS.Network import Network\n",
    "from HOTS.KmeansLagorce import KmeansLagorce\n",
    "from HOTS.KmeansMaro import KmeansMaro\n",
    "from HOTS.conv2eve import conv2eve\n",
    "\n",
    "tau = 9e-4 # -> tau=1ms, si on prend 10 ms on est à 1s pour la dernière couche et les vidéos font 0.3s en moyenne\n",
    "R = 2\n",
    "filthr = 2\n",
    "nbkNN = 3\n",
    "algo = 'lagorce'\n",
    "decay = 'exponential'\n",
    "hom = True\n",
    "krnlinit = 'rdn'\n",
    "nb_cluster = [4, 8, 16]\n",
    "ImageSize = (34, 34)\n",
    "DataPath = 'Data/testsetnmnist.p'\n",
    "\n",
    "NbClusteringData = 15\n",
    "NbTrainingData = 40\n",
    "NbTestingData = 40\n",
    "_1ofich = True\n",
    "event_tr, event_te, event_cl, label_tr, label_te = LoadNMNIST(\n",
    "NbTrainingData, NbTestingData, NbClusteringData, OneOfEach=_1ofich, Path=DataPath, OutOnePolarity=False, ListPolarities=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records/EXP_03_NMNIST/20201021_hots_0.9ms_lagorce.pkl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Records/EXP_03_NMNIST/20201021_hots_0.9ms_lagorce.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9db67cc885cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mevent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_cl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNbClusterList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_record\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNbCycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         )\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mSaveObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClusterLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mClusterLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassif0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/quantic/science/HomeHots/HOTS_clone_laurent/HOTS/Tools.py\u001b[0m in \u001b[0;36mSaveObject\u001b[0;34m(obj, filename)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSaveObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Records/EXP_03_NMNIST/20201021_hots_0.9ms_lagorce.pkl'"
     ]
    }
   ],
   "source": [
    "#timestr = time.strftime(\"%Y%m%d\")\n",
    "hom = False\n",
    "timestr = '20201021'\n",
    "if hom==True:\n",
    "    fname = 'Records/EXP_03_NMNIST/'+timestr+'_hots_'+str(tau*1000)+'ms_'+algo+'_homeo.pkl'\n",
    "else:\n",
    "    fname = 'Records/EXP_03_NMNIST/'+timestr+'_hots_'+str(tau*1000)+'ms_'+algo+'.pkl'\n",
    "print(fname)\n",
    "\n",
    "L1 = ClusteringLayer(tau=tau,R=R,verbose=0,ThrFilter=filthr,LearningAlgo=algo,kernel=decay,homeo=hom,init=krnlinit)\n",
    "L2 = ClusteringLayer(tau=10 * tau,R=2 * R,verbose=0,ThrFilter=filthr,LearningAlgo=algo,kernel=decay,homeo=hom,init=krnlinit)\n",
    "L3 = ClusteringLayer(tau=10 * 10 * tau,R=2 * 2 * R,verbose=0,ThrFilter=filthr,LearningAlgo=algo,kernel=decay,homeo=hom,init=krnlinit)\n",
    "Net = Network([L1, L2, L3])\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    ClusterLayer, event_output = Net.TrainCluster(\n",
    "            event=event_cl, NbClusterList=nb_cluster, to_record=True, NbCycle=1\n",
    "        )\n",
    "    SaveObject(ClusterLayer, fname)\n",
    "else: \n",
    "    ClusterLayer, Classif0 = LoadObject(fname)\n",
    "\n",
    "prediction, accuracy, method = Classif0.HistogramDistance(knn=nbkNN, to_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading only on digit of each for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homrun = False\n",
    "event0_o_tr2 = Net.RunNetwork(event_tr, NbClusterList=ClusterLayer, homrun=homrun)\n",
    "event0_o_te2 = Net.RunNetwork(event_te, NbClusterList=ClusterLayer, homrun=homrun)\n",
    "Classif02 = Classifier(event0_o_tr2, event0_o_te2, TrainingLabel=label_tr, GroundTruth=label_te)\n",
    "prediction2, accuracy2, method2 = Classif02.HistogramDistance(knn=nbkNN, to_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building matrix for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlen = ImageSize[0]*ImageSize[1]\n",
    "taucla = 1e-2\n",
    "X = np.zeros([len(Classif02.event_train.time), imlen*nb_cluster[-1]])\n",
    "y = np.zeros([len(Classif02.event_train.time)])\n",
    "addr = Classif02.event_train.address[0]*ImageSize[0]+Classif02.event_train.address[1]+imlen*Classif02.event_train.polarity[0]\n",
    "X[0][addr]=1\n",
    "y[0] = Classif02.GroundTruth[0]\n",
    "il = 0\n",
    "for i in range(1,len(Classif02.event_train.time)):\n",
    "    if i-1 not in Classif02.event_train.ChangeIdx:\n",
    "        X[i] = X[i-1]*np.exp((Classif02.event_train.time[i-1]-Classif02.event_train.time[i])/taucla)\n",
    "    else:\n",
    "        il += 1\n",
    "    addr = Classif02.event_train.address[i][0]*ImageSize[0]+Classif02.event_train.address[i][1]+imlen*Classif02.event_train.polarity[i]\n",
    "    X[i][addr] = 1\n",
    "    y[i] = Classif02.GroundTruth[il]\n",
    "plt.imshow(X[:10000]);\n",
    "print('Number of events: '+str(X.shape [0])+' - Number of features: '+str(X.shape [1]))\n",
    "SaveObject([X,y], 'vectorzLR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building subsampled matrix for logistic regression (taking 1 sample over 'subcoef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcoef = 10\n",
    "Xlr, ylr = LoadObject('vectorzLR.pkl')\n",
    "Xlrsub = Xlr[::subcoef,:]\n",
    "ylrsub = ylr[::subcoef]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building matrix for logistic regression taking only polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taucla = 1e-2\n",
    "Xhisto = np.zeros([len(Classif02.event_train.time), nb_cluster[-1]])\n",
    "yhisto = np.zeros([len(Classif02.event_train.time)])\n",
    "addr = Classif02.event_train.polarity[0]\n",
    "Xhisto[0][addr]=1\n",
    "yhisto[0] = Classif02.GroundTruth[0]\n",
    "il = 0\n",
    "for i in range(1,len(Classif02.event_train.time)):\n",
    "    if i-1 not in Classif02.event_train.ChangeIdx:\n",
    "        Xhisto[i] = Xhisto[i-1]*np.exp((Classif02.event_train.time[i-1]-Classif02.event_train.time[i])/taucla)\n",
    "    else:\n",
    "        il += 1\n",
    "    addr = Classif02.event_train.polarity[i]\n",
    "    Xhisto[i][addr] = 1\n",
    "    yhisto[i] = Classif02.GroundTruth[il]\n",
    "print('Number of events: '+str(Xhisto.shape [0])+' - Number of features: '+str(Xhisto.shape [1]))\n",
    "SaveObject([Xhisto,yhisto], 'vecthistLR.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV as LogReg\n",
    "\n",
    "lrsub = LogReg(random_state=0).fit(Xlr,ylr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on the subsampled matrix using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV as LogReg\n",
    "\n",
    "lrsub = LogReg(random_state=0).fit(Xlrsub,ylrsub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on the matrix of polarities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "lrpol = LR(random_state=0).fit(Xhisto,yhisto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpol.score(Xhisto,yhisto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from HOTS.Tools import GenerateHistogram\n",
    "histo_train, pola_train = GenerateHistogram(Classif0.event_train)\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(histo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = []\n",
    "a = np.dot(histo_train,pca.components_.T)\n",
    "for i in range(10):\n",
    "    ilab = np.where(Classif0.GroundTruth==[str(float(i))])[0]\n",
    "    scatx = np.zeros([len(ilab)])\n",
    "    scaty = np.zeros([len(ilab)])\n",
    "    k=0\n",
    "    for j in ilab:\n",
    "        scatx[k] = a[j][0]\n",
    "        scaty[k] = a[j][1]\n",
    "        k+=1\n",
    "    ax += plt.plot(scatx,scaty, '*', label=str(i))\n",
    "labelz = [l.get_label() for l in ax]\n",
    "plt.legend(ax, labelz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classif0.event_train.ChangeIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from HOTS.Tools import GenerateHistogram\n",
    "nbevents = 500\n",
    "output = np.zeros([Classif0.event_train.ChangeIdx.shape[0],nbevents])\n",
    "output[0] = Classif0.event_train.polarity[:nbevents]\n",
    "for i in range(Classif0.event_train.ChangeIdx.shape[0]):\n",
    "    output[i] = Classif0.event_train.polarity[Classif0.event_train.ChangeIdx[i]:Classif0.event_train.ChangeIdx[i]+nbevents]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = []\n",
    "a = np.dot(output,pca.components_.T)\n",
    "for i in range(10):\n",
    "    ilab = np.where(Classif0.GroundTruth==[str(float(i))])[0]\n",
    "    scatx = np.zeros([len(ilab)])\n",
    "    scaty = np.zeros([len(ilab)])\n",
    "    k=0\n",
    "    for j in ilab:\n",
    "        scatx[k] = a[j][0]\n",
    "        scaty[k] = a[j][1]\n",
    "        k+=1\n",
    "    ax += plt.plot(scatx,scaty, '*', label=str(i))\n",
    "labelz = [l.get_label() for l in ax]\n",
    "plt.legend(ax, labelz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1e-5,1e-4,5e-4,1e-3,2.5e-3,4e-3,5e-3,1e-2,2e-2]\n",
    "for idx in a:\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*map(lambda x: 3 * x**2, Classif0.event_train.ChangeIdx),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones([10])*100\n",
    "for i in range(200):\n",
    "    if i in a:\n",
    "        print(i, np.where(a==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "N = 4\n",
    "valmin = 0.7\n",
    "valmax = 1.3\n",
    "n = 1\n",
    "p = 1\n",
    "x = np.linspace(0,1,50)\n",
    "f1 = np.exp((x-1/N)*-N)\n",
    "N = 8\n",
    "f2 = np.exp((x-1/N)*N)\n",
    "N = 16\n",
    "f3 = np.exp((x-1/N)*N)\n",
    "N = 32\n",
    "f4 = np.exp((x-1/N)*N)\n",
    "j1 = np.log(np.exp(1)*(N-1)*x/(p-x/p))\n",
    "p = 2\n",
    "j2 = np.log(np.exp(1)*(N-1)*x/(p-x/p))\n",
    "p = 3\n",
    "j3 = np.log(np.exp(1)*(N-1)*x/(p-x/p))\n",
    "b = np.log(valmax)*np.log(valmin)/((N-1)*np.log(valmin)+np.log(valmax))\n",
    "d = b/np.log(valmin)\n",
    "a = -b*N\n",
    "k = np.exp((a*x+b)/(d-x))\n",
    "valmin = 0.6\n",
    "valmax = 2*1.4\n",
    "b = np.log(valmax)*np.log(valmin)/((N-1)*np.log(valmin)+np.log(valmax))\n",
    "d = b/np.log(valmin)\n",
    "a = -b*N\n",
    "k2 = np.exp((a*x+b)/(d-x))\n",
    "valmin = 0.5\n",
    "valmax = 2*1.5\n",
    "b = np.log(valmax)*np.log(valmin)/((N-1)*np.log(valmin)+np.log(valmax))\n",
    "d = b/np.log(valmin)\n",
    "a = -b*N\n",
    "k3 = np.exp((a*x+b)/(d-x))\n",
    "l = np.log(x+0.2)\n",
    "m = -np.log(1-(x+0.2))\n",
    "N = 8\n",
    "h = np.log(x)/np.log(1/N)\n",
    "plt.plot(x,f1, x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones([20,2])*25\n",
    "print(np.sum(a)*a)\n",
    "print(np.sum(np.sqrt(a), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
