{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laurent/quantic/science/HomeHots/HOTS_clone_laurent/HOTS\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from mix_Network import *\n",
    "\n",
    "dataset = 'nmnist'\n",
    "records_path = '../Records/'\n",
    "timestr = datetime.datetime.now().date().isoformat()\n",
    "timestr = '2020-11-25'\n",
    "algo = 'lagorce'\n",
    "\n",
    "ds = 10\n",
    "ds = 75\n",
    "\n",
    "NbTrainingData = 7500//ds\n",
    "NbTestingData = 2500//ds\n",
    "\n",
    "tau = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmnist(NbTrainingData, NbTestingData):\n",
    "    class eventV(object):\n",
    "            def __init__(self, nbevt):\n",
    "                self.time = np.zeros((nbevt))\n",
    "                self.address = np.zeros((nbevt, 2))\n",
    "                self.polarity = np.zeros((nbevt))\n",
    "                self.ImageSize = [34,34]\n",
    "                self.ListPolarities = [0,1]\n",
    "                \n",
    "    learningset = tonic.datasets.NMNIST(save_to='../Data/',\n",
    "                                train=False,\n",
    "                                transform=None)\n",
    "    loader = tonic.datasets.DataLoader(learningset, shuffle=True)\n",
    "    \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTrainingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_train = eventV(nbtot)\n",
    "    labels_train = []\n",
    "    idx = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_train.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_train.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_train.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_train.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_train.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "            \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTestingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTestingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_test = eventV(nbtot)\n",
    "    labels_test = []\n",
    "    idx = 0\n",
    "    for i in range(NbTestingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_test.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_test.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_test.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_test.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_test.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "    events_cluster = []\n",
    "    return [events_train, events_test, events_cluster, labels_train, labels_test]\n",
    "\n",
    "# ### Building matrix for logistic regression\n",
    "def gather_data(events_in, labels_in,\n",
    "                tau_cla=.150, # characteristic time of a digit\n",
    "                sample_events=50, sample_space = 1,\n",
    "                verbose=False, debug=False):\n",
    "\n",
    "    n_events = events_in.time.shape[0]\n",
    "\n",
    "    c_int = lambda n, d : ((n - 1) // d) + 1\n",
    "    data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data\n",
    "\n",
    "    X = np.zeros((c_int(n_events, sample_events), len(data.ravel())))\n",
    "    y = np.zeros((c_int(n_events, sample_events), ))\n",
    "\n",
    "    for i_event in range(1, n_events):\n",
    "        if events_in.time[i_event]<events_in.time[i_event-1]:\n",
    "            data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data \n",
    "\n",
    "        data *= np.exp(-(events_in.time[i_event]-events_in.time[i_event-1])/tau_cla)\n",
    "        x_pos = events_in.address[i_event, 0]//sample_space\n",
    "        y_pos = events_in.address[i_event, 1]//sample_space\n",
    "        p = events_in.polarity[i_event]\n",
    "        data[int(x_pos), int(y_pos), int(p)] = 1.\n",
    "\n",
    "        if i_event % sample_events == sample_events//2 :\n",
    "            if debug:\n",
    "                print(f'DEBUG {i_event} {i_event//sample_events} ')\n",
    "                print(f'DEBUG {y[i_event//sample_events]}   ')\n",
    "                print(f'DEBUG  {labels_in[i_event]} ')\n",
    "            X[i_event//sample_events, :] = data.ravel()\n",
    "            y[i_event//sample_events] = labels_in[i_event]\n",
    "            \n",
    "    if verbose: print('Number of events: ' + str(X.shape[0])+' - Number of features: ' + str(X.shape[1]))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ### Performingxlogistic regression\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "#\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "# \n",
    "opts_LR = dict(max_iter=2000, # random_state=0,\n",
    "               n_jobs=-1, class_weight='balanced')\n",
    "#opts_LR['Cs'] = 5\n",
    "opts_LR['Cs'] = 32\n",
    "# TODO for a publication use 100 from 10^{-10} to 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tic():\n",
    "    global ttic\n",
    "    ttic = time.time()\n",
    "def toc():\n",
    "    print(f'Done in {time.time() - ttic:.3f} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n"
     ]
    }
   ],
   "source": [
    "homeo = False\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader, order = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader, order = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train = hots.training(loader, order, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test = hots.training(loader, order, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train, out_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeo = True\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader, order = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader, order = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train = hots.training(loader, order, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test = hots.training(loader, order, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train, out_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on raw input spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "dataset = get_nmnist(NbTrainingData, NbTestingData)\n",
    "events_train, events_test, events_cluster, labels_train, labels_test = dataset\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "X_train, y_train = gather_data(events_train, labels_train, verbose=verbose)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "lr = LR(**opts_LR).fit(X_train, y_train)\n",
    "print(f'Classification score for raw input is {lr.score(X_train, y_train):.3f} (train)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic()\n",
    "X_test, y_test = gather_data(events_test, labels_test, verbose=verbose)\n",
    "print(f'Classification score for raw input is {lr.score(X_test, y_test):.3f} (test)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression with or without homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'homeo={homeo}')\n",
    "    print(40*'-')\n",
    "    if homeo == True:\n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train_hom[0], out_test_hom[0], out_train_hom[1], out_test_hom[1]\n",
    "    else: \n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train[0], out_test[0], out_train[1], out_test[1]\n",
    "        \n",
    "    X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "    print(X_train.shape)\n",
    "    lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "    \n",
    "    X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
