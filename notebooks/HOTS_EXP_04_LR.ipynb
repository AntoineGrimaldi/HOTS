{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joe/Documents/boulot/git/homhots/HOTS/HOTS\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from mix_Network import *\n",
    "\n",
    "dataset = 'nmnist'\n",
    "records_path = '../Records'\n",
    "timestr = datetime.datetime.now().date().isoformat()\n",
    "timestr = '2020-12-21'\n",
    "verbose = True\n",
    "\n",
    "homeo = True\n",
    "sigma = None\n",
    "pooling = False\n",
    "homeinv = False\n",
    "jitter = False\n",
    "tau = 5\n",
    "nb_train = 500\n",
    "nb_test = 100\n",
    "krnlinit = 'first'\n",
    "nblay = 3\n",
    "nbclust = 4\n",
    "\n",
    "ds = 75\n",
    "nb_train = 7500//ds\n",
    "nb_test = 2500//ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmnist(NbTrainingData, NbTestingData):\n",
    "    class eventV(object):\n",
    "            def __init__(self, nbevt):\n",
    "                self.time = np.zeros((nbevt))\n",
    "                self.address = np.zeros((nbevt, 2))\n",
    "                self.polarity = np.zeros((nbevt))\n",
    "                self.ImageSize = [34,34]\n",
    "                self.ListPolarities = [0,1]\n",
    "                \n",
    "    learningset = tonic.datasets.NMNIST(save_to='../Data/',\n",
    "                                train=False,\n",
    "                                transform=None)\n",
    "    loader = tonic.datasets.DataLoader(learningset, shuffle=True)\n",
    "    \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTrainingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_train = eventV(nbtot)\n",
    "    labels_train = []\n",
    "    idx = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_train.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_train.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_train.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_train.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_train.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "            \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTestingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTestingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_test = eventV(nbtot)\n",
    "    labels_test = []\n",
    "    idx = 0\n",
    "    for i in range(NbTestingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_test.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_test.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_test.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_test.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_test.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "    events_cluster = []\n",
    "    return [events_train, events_test, events_cluster, labels_train, labels_test]\n",
    "\n",
    "#### Building matrix for logistic regression\n",
    "def gather_data(events_in, labels_in,\n",
    "                tau_cla=150, # characteristic time of a digit\n",
    "                sample_events=50, sample_space = 1,\n",
    "                verbose=False, debug=False):\n",
    "\n",
    "    tau_cla *= 1e3 # to enter tau in ms\n",
    "    n_events = events_in.time.shape[0]\n",
    "\n",
    "    c_int = lambda n, d : ((n - 1) // d) + 1\n",
    "    data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data\n",
    "\n",
    "    X = np.zeros((c_int(n_events, sample_events), len(data.ravel())))\n",
    "    y = np.zeros((c_int(n_events, sample_events), ))\n",
    "\n",
    "    for i_event in range(1, n_events):\n",
    "        if events_in.time[i_event]<events_in.time[i_event-1]:\n",
    "            data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data \n",
    "\n",
    "        data *= np.exp(-(events_in.time[i_event]-events_in.time[i_event-1])/tau_cla)\n",
    "        \n",
    "        x_pos = events_in.address[i_event, 0]//sample_space\n",
    "        y_pos = events_in.address[i_event, 1]//sample_space\n",
    "        p = events_in.polarity[i_event]\n",
    "        data[int(x_pos), int(y_pos), int(p)] = 1.\n",
    "\n",
    "        if i_event % sample_events == sample_events//2 :\n",
    "            if debug:\n",
    "                print(f'DEBUG {i_event} {i_event//sample_events} ')\n",
    "                print(f'DEBUG {y[i_event//sample_events]}   ')\n",
    "                print(f'DEBUG  {labels_in[i_event]} ')\n",
    "            X[i_event//sample_events, :] = data.ravel()\n",
    "            y[i_event//sample_events] = labels_in[i_event]\n",
    "            \n",
    "    if verbose: print('Number of events: ' + str(X.shape[0])+' - Number of features: ' + str(X.shape[1]))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_events(tau, krnlinit, nblay, nbclust, homeo, records_path, timestr, dataset, sigma, homeinv, jitter, nb_train, nb_test):\n",
    "    hotshom = network(krnlinit=krnlinit, tau=tau, nblay=nblay, nbclust=nbclust, homeo=homeo, sigma=sigma, homeinv=homeinv, jitter=jitter)\n",
    "    arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "    fname = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{dataset}_{arch}_{tau}_{homeo}_{sigma}_{homeinv}_{jitter}'\n",
    "    print(fname)\n",
    "    if not os.path.isfile(fname+'_model.pkl'):\n",
    "        loaderhom, order = hotshom.learning1by1(dataset=dataset)\n",
    "        with open(fname+'_model.pkl', 'wb') as file:\n",
    "            pickle.dump([hotshom, loaderhom, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname+'_model.pkl', 'rb') as file:\n",
    "            hotshom, loaderhom, order = pickle.load(file)\n",
    "            \n",
    "    if not os.path.isfile(fname+f'_evout_{nb_train}_{nb_test}.pkl'):       \n",
    "        _, loaderhom, out_train = hotshom.training(loaderhom, order, nb_digit = nb_train, LR=True)\n",
    "        _, loaderhom, out_test = hotshom.training(loaderhom, order, nb_digit = nb_test, LR=True)\n",
    "        with open(fname+f'_evout_{nb_train}_{nb_test}.pkl', 'wb') as file:\n",
    "            pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname+f'_evout_{nb_train}_{nb_test}.pkl', 'rb') as file:\n",
    "            out_train, out_test = pickle.load(file)\n",
    "    return out_train[0], out_test[0], out_train[1], out_test[1]\n",
    "\n",
    "\n",
    "# ### Performingxlogistic regression\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "#\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "# \n",
    "opts_LR = dict(max_iter=2000, # random_state=0,\n",
    "               n_jobs=-1, class_weight='balanced')\n",
    "#opts_LR['Cs'] = 5\n",
    "opts_LR['Cs'] = 32\n",
    "# TODO for a publication use 100 from 10^{-10} to 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tic():\n",
    "    global ttic\n",
    "    ttic = time.time()\n",
    "def toc():\n",
    "    print(f'Done in {time.time() - ttic:.3f} s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on raw input spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n",
      "Done in 35.425 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "dataset = get_nmnist(nb_train, nb_test)\n",
    "events_train, events_test, events_cluster, labels_train, labels_test = dataset\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 8547 - Number of features: 2312\n",
      "Done in 6.284 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "X_train, y_train = gather_data(events_train, labels_train, verbose=verbose)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score for raw input is 0.999 (train)\n",
      "Done in 650.001 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "lr = LR(**opts_LR).fit(X_train, y_train)\n",
    "print(f'Classification score for raw input is {lr.score(X_train, y_train):.3f} (train)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 2790 - Number of features: 2312\n",
      "Classification score for raw input is 0.543 (test)\n",
      "Done in 1.601 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "X_test, y_test = gather_data(events_test, labels_test, verbose=verbose)\n",
    "print(f'Classification score for raw input is {lr.score(X_test, y_test):.3f} (test)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression with or without homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "homeo=False\n",
      "----------------------------------------\n",
      "../Records/EXP_03_NMNIST/2020-12-21_hots_nmnist_[4, 8, 16]_5_False_None_False_False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e465da57d0041ad8e2e9710c609d9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59d011afae8455fa89ff203b331e575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of events: 7853 - Number of features: 18496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 48.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score for homeo = False is 1.000 (train)\n",
      "Number of events: 2615 - Number of features: 18496\n",
      "Classification score for homeo = False is 0.556 (test)\n",
      "----------------------------------------\n",
      "homeo=True\n",
      "----------------------------------------\n",
      "../Records/EXP_03_NMNIST/2020-12-21_hots_nmnist_[4, 8, 16]_5_True_None_False_False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4eb44ef5bf49d989218b9b2d430f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613b336d53664093a70737d622486140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of events: 8087 - Number of features: 18496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 42.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score for homeo = True is 0.999 (train)\n",
      "Number of events: 2407 - Number of features: 18496\n",
      "Classification score for homeo = True is 0.742 (test)\n"
     ]
    }
   ],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'homeo={homeo}')\n",
    "    print(40*'-')\n",
    "    events_train_o, events_test_o, labels_train, labels_test = get_events(tau, krnlinit, nblay, nbclust, homeo, records_path, timestr, dataset, sigma, homeinv, jitter, nb_train, nb_test)\n",
    "        \n",
    "    X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "\n",
    "    lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "    \n",
    "    X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
