{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joe/Documents/boulot/git/homhots/HOTS/HOTS\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from mix_Network import *\n",
    "\n",
    "dataset = 'nmnist'\n",
    "records_path = '../Records'\n",
    "timestr = datetime.datetime.now().date().isoformat()\n",
    "timestr = '2020-11-25'\n",
    "algo = 'lagorce'\n",
    "\n",
    "ds = 10\n",
    "ds = 75\n",
    "\n",
    "NbTrainingData = 7500//ds\n",
    "NbTestingData = 2500//ds\n",
    "\n",
    "tau = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmnist(NbTrainingData, NbTestingData):\n",
    "    class eventV(object):\n",
    "            def __init__(self, nbevt):\n",
    "                self.time = np.zeros((nbevt))\n",
    "                self.address = np.zeros((nbevt, 2))\n",
    "                self.polarity = np.zeros((nbevt))\n",
    "                self.ImageSize = [34,34]\n",
    "                self.ListPolarities = [0,1]\n",
    "                \n",
    "    learningset = tonic.datasets.NMNIST(save_to='../Data/',\n",
    "                                train=False,\n",
    "                                transform=None)\n",
    "    loader = tonic.datasets.DataLoader(learningset, shuffle=True)\n",
    "    \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTrainingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_train = eventV(nbtot)\n",
    "    labels_train = []\n",
    "    idx = 0\n",
    "    for i in range(NbTrainingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_train.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_train.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_train.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_train.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_train.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "            \n",
    "    eventslist = [next(iter(loader)) for i in range(NbTestingData)]\n",
    "    nbtot = 0\n",
    "    for i in range(NbTestingData):\n",
    "        nbtot+=eventslist[i][0].shape[1]\n",
    "    events_test = eventV(nbtot)\n",
    "    labels_test = []\n",
    "    idx = 0\n",
    "    for i in range(NbTestingData):\n",
    "        for j in range(eventslist[i][0].shape[1]):\n",
    "            events_test.address[idx,0] = eventslist[i][0][0,j,0].item()\n",
    "            events_test.address[idx,1] = eventslist[i][0][0,j,1].item()\n",
    "            events_test.time[idx] = eventslist[i][0][0,j,2].item()*1e-6\n",
    "            events_test.polarity[idx] = eventslist[i][0][0,j,3].item()\n",
    "            labels_test.append(eventslist[i][1])\n",
    "            idx+=1\n",
    "    events_cluster = []\n",
    "    return [events_train, events_test, events_cluster, labels_train, labels_test]\n",
    "\n",
    "# ### Building matrix for logistic regression\n",
    "def gather_data(events_in, labels_in,\n",
    "                tau_cla=.150, # characteristic time of a digit\n",
    "                sample_events=50, sample_space = 1,\n",
    "                verbose=False, debug=False):\n",
    "\n",
    "    n_events = events_in.time.shape[0]\n",
    "\n",
    "    c_int = lambda n, d : ((n - 1) // d) + 1\n",
    "    data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data\n",
    "\n",
    "    X = np.zeros((c_int(n_events, sample_events), len(data.ravel())))\n",
    "    y = np.zeros((c_int(n_events, sample_events), ))\n",
    "\n",
    "    for i_event in range(1, n_events):\n",
    "        if events_in.time[i_event]<events_in.time[i_event-1]:\n",
    "            data = np.zeros((c_int(events_in.ImageSize[0], sample_space),\n",
    "                     c_int(events_in.ImageSize[1], sample_space),\n",
    "                     len(events_in.ListPolarities))) #tmp data \n",
    "\n",
    "        data *= np.exp(-(events_in.time[i_event]-events_in.time[i_event-1])/tau_cla)\n",
    "        x_pos = events_in.address[i_event, 0]//sample_space\n",
    "        y_pos = events_in.address[i_event, 1]//sample_space\n",
    "        p = events_in.polarity[i_event]\n",
    "        data[int(x_pos), int(y_pos), int(p)] = 1.\n",
    "\n",
    "        if i_event % sample_events == sample_events//2 :\n",
    "            if debug:\n",
    "                print(f'DEBUG {i_event} {i_event//sample_events} ')\n",
    "                print(f'DEBUG {y[i_event//sample_events]}   ')\n",
    "                print(f'DEBUG  {labels_in[i_event]} ')\n",
    "            print(data[:,:,1])\n",
    "            X[i_event//sample_events, :] = data.ravel()\n",
    "            y[i_event//sample_events] = labels_in[i_event]\n",
    "            \n",
    "    if verbose: print('Number of events: ' + str(X.shape[0])+' - Number of features: ' + str(X.shape[1]))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ### Performingxlogistic regression\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "#\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "# \n",
    "opts_LR = dict(max_iter=2000, # random_state=0,\n",
    "               n_jobs=-1, class_weight='balanced')\n",
    "#opts_LR['Cs'] = 5\n",
    "opts_LR['Cs'] = 32\n",
    "# TODO for a publication use 100 from 10^{-10} to 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tic():\n",
    "    global ttic\n",
    "    ttic = time.time()\n",
    "def toc():\n",
    "    print(f'Done in {time.time() - ttic:.3f} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:27<00:00,  1.87s/it]\n",
      "100%|██████████| 15/15 [00:34<00:00,  2.29s/it]\n",
      "100%|██████████| 15/15 [01:12<00:00,  4.86s/it]\n",
      "100%|██████████| 100/100 [06:24<00:00,  3.85s/it]\n",
      "100%|██████████| 33/33 [01:47<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "homeo = False\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader, order = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader, order = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train = hots.training(loader, order, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test = hots.training(loader, order, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train, out_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:18<00:00,  1.21s/it]\n",
      "100%|██████████| 15/15 [00:33<00:00,  2.23s/it]\n",
      "100%|██████████| 15/15 [01:06<00:00,  4.41s/it]\n",
      "100%|██████████| 100/100 [06:31<00:00,  3.92s/it]\n",
      "100%|██████████| 33/33 [01:58<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "homeo = True\n",
    "\n",
    "fname_ = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{tau}_ms_{NbTrainingData}_{NbTestingData}'\n",
    "label = '_homeo' if homeo else ''\n",
    "fname_model = fname_ + '_model_' + algo + label + '.pkl'\n",
    "fname_event0_o = fname_ + '_event_out_' + algo + label + '.pkl'\n",
    "\n",
    "hots = network(krnlinit='first', tau=tau, homeo=homeo)\n",
    "if not os.path.isfile(fname_model):\n",
    "    loader, order = hots.learning1by1(dataset=dataset)\n",
    "    with open(fname_model, 'wb') as file:\n",
    "        pickle.dump([hots, loader, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_model, 'rb') as file:\n",
    "        hots, loader, order = pickle.load(file)\n",
    "if not os.path.isfile(fname_event0_o):\n",
    "    _ , loader, out_train = hots.training(loader, order, LR=True, nb_digit = NbTrainingData)\n",
    "    _ , loader, out_test = hots.training(loader, order, LR=True, nb_digit = NbTestingData)\n",
    "    with open(fname_event0_o, 'wb') as file:\n",
    "        pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(fname_event0_o, 'rb') as file:\n",
    "        out_train, out_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression on raw input spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n",
      "Done in 30.325 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "dataset = get_nmnist(NbTrainingData, NbTestingData)\n",
    "events_train, events_test, events_cluster, labels_train, labels_test = dataset\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 3.864 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "X_train, y_train = gather_data(events_train, labels_train, verbose=verbose)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score for raw input is 0.999 (train)\n",
      "Done in 2094.026 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "lr = LR(**opts_LR).fit(X_train, y_train)\n",
    "print(f'Classification score for raw input is {lr.score(X_train, y_train):.3f} (train)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score for raw input is 0.327 (test)\n",
      "Done in 1.630 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "X_test, y_test = gather_data(events_test, labels_test, verbose=verbose)\n",
    "print(f'Classification score for raw input is {lr.score(X_test, y_test):.3f} (test)')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing logistic regression with or without homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "homeo=False\n",
      "----------------------------------------\n",
      "(7560, 18496)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dfade93bb771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_train_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Classification score for homeo = {homeo} is {lr.score(X_train, y_train):.3f} (train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1897\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                       )\n\u001b[0;32m-> 1899\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m             for l1_ratio in l1_ratios_)\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for homeo in [False, True]:\n",
    "    print(40*'-')\n",
    "    print(f'homeo={homeo}')\n",
    "    print(40*'-')\n",
    "    if homeo == True:\n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train_hom[0], out_test_hom[0], out_train_hom[1], out_test_hom[1]\n",
    "    else: \n",
    "        events_train_o, events_test_o, labels_train, labels_test = out_train[0], out_test[0], out_train[1], out_test[1]\n",
    "        \n",
    "    X_train, y_train = gather_data(events_train_o, labels_train, verbose=verbose)\n",
    "    print(X_train.shape)\n",
    "    lr = LR(**opts_LR, verbose=verbose).fit(X_train, y_train)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_train, y_train):.3f} (train)')\n",
    "    \n",
    "    X_test, y_test = gather_data(events_test_o, labels_test, verbose=verbose)\n",
    "    print(f'Classification score for homeo = {homeo} is {lr.score(X_test, y_test):.3f} (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
