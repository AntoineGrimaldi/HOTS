{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antoine/homhots/HOTS/HOTS\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd '../HOTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from mix_Network import *\n",
    "\n",
    "dataset = 'nmnist'\n",
    "records_path = '../Records'\n",
    "timestr = datetime.datetime.now().date().isoformat()\n",
    "timestr = '2020-12-21'\n",
    "verbose = True\n",
    "\n",
    "%mkdir -p ../Records\n",
    "%mkdir -p ../Records/EXP_03_NMNIST\n",
    "\n",
    "homeo = True\n",
    "sigma = None\n",
    "pooling = False\n",
    "homeinv = False\n",
    "jitter = False\n",
    "tau = 5\n",
    "krnlinit = 'first'\n",
    "nblay = 3\n",
    "nbclust = 4\n",
    "\n",
    "ds = 75\n",
    "nb_train = 7500//ds\n",
    "nb_test = 2500//ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmnist(NbTrainingData, NbTestingData):\n",
    "    def loadev(nbdigit, loader, learningset):\n",
    "        timout = []\n",
    "        xout = []\n",
    "        yout = []\n",
    "        polout = []\n",
    "        labout = []\n",
    "        for i in range(NbTrainingData):\n",
    "            events, target = next(iter(loader))\n",
    "            for iev in range(events.shape[1]):\n",
    "                    timout.append(events[0][iev][learningset.ordering.find(\"t\")].item())\n",
    "                    xout.append(events[0][iev][learningset.ordering.find(\"x\")].item())\n",
    "                    yout.append(events[0][iev][learningset.ordering.find(\"y\")].item())\n",
    "                    polout.append(events[0][iev][learningset.ordering.find(\"p\")].item())\n",
    "                    labout.append(target.item())\n",
    "\n",
    "        eventsout = [xout,yout,timout,polout,labout,learningset.sensor_size,2]\n",
    "        return eventsout\n",
    "    \n",
    "    learningset = tonic.datasets.NMNIST(save_to='../Data/',\n",
    "                                    train=False,\n",
    "                                    transform=None)\n",
    "    loader = tonic.datasets.DataLoader(learningset, shuffle=True)\n",
    "    \n",
    "    events_train = loadev(NbTrainingData, loader, learningset)\n",
    "    events_test = loadev(NbTestingData, loader, learningset)\n",
    "    \n",
    "    return events_train, events_test\n",
    "\n",
    "#### Building matrix for logistic regression\n",
    "def gather_data(events_in,\n",
    "                tau_cla=150, # characteristic time of a digit\n",
    "                sample_events=50, sample_space = 1,\n",
    "                verbose=False, debug=False):\n",
    "    tau_cla *= 1e3 # to enter tau in ms\n",
    "    n_events = len(events_in[0])\n",
    "\n",
    "    c_int = lambda n, d : ((n - 1) // d) + 1\n",
    "    \n",
    "    data = np.zeros((c_int(events_in[-2][0], sample_space),\n",
    "                     c_int(events_in[-2][1], sample_space),\n",
    "                     events_in[-1])) #tmp data\n",
    "\n",
    "    X = np.zeros((c_int(n_events, sample_events), len(data.ravel())))\n",
    "    y = np.zeros((c_int(n_events, sample_events), ))\n",
    "\n",
    "    for i_event in range(1, n_events):\n",
    "        if events_in[2][i_event]<events_in[2][i_event-1]:\n",
    "            data = np.zeros((c_int(events_in[-2][0], sample_space),\n",
    "                     c_int(events_in[-2][1], sample_space),\n",
    "                     events_in[-1])) #tmp data \n",
    "\n",
    "        data *= np.exp(-(events_in[2][i_event]-events_in[2][i_event-1])/tau_cla)\n",
    "        \n",
    "        x_pos = events_in[0][i_event]//sample_space\n",
    "        y_pos = events_in[1][i_event]//sample_space\n",
    "        p = events_in[3][i_event]\n",
    "        data[int(x_pos), int(y_pos), int(p)] = 1.\n",
    "\n",
    "        if i_event % sample_events == sample_events//2 :\n",
    "            if debug:\n",
    "                print(f'DEBUG {i_event} {i_event//sample_events} ')\n",
    "                print(f'DEBUG {y[i_event//sample_events]}   ')\n",
    "                print(f'DEBUG  {events_in[-3][i_event]} ')\n",
    "            X[i_event//sample_events, :] = data.ravel()\n",
    "            y[i_event//sample_events] = events_in[-3][i_event]\n",
    "            \n",
    "    if verbose: print('Number of events: ' + str(X.shape[0])+' - Number of features: ' + str(X.shape[1]))\n",
    "    \n",
    "    y_out = np.zeros([y.shape[0],int(max(y)+1)])\n",
    "    for i in range(y.shape[0]):\n",
    "        y_out[i,int(y[i])]=1\n",
    "    \n",
    "    return X, y_out\n",
    "\n",
    "def get_events(tau, krnlinit, nblay, nbclust, homeo, records_path, timestr, dataset, sigma, homeinv, jitter, nb_train, nb_test):\n",
    "    hotshom = network(krnlinit=krnlinit, tau=tau, nblay=nblay, nbclust=nbclust, homeo=homeo, sigma=sigma, homeinv=homeinv, jitter=jitter)\n",
    "    arch = [hotshom.L[i].kernel.shape[1] for i in range(len(hotshom.L))]\n",
    "    fname = f'{records_path}/EXP_03_NMNIST/{timestr}_hots_{dataset}_{arch}_{tau}_{homeo}_{sigma}_{homeinv}_{jitter}'\n",
    "    print(fname)\n",
    "    if not os.path.isfile(fname+'_model.pkl'):\n",
    "        loaderhom, order = hotshom.learning1by1(dataset=dataset)\n",
    "        with open(fname+'_model.pkl', 'wb') as file:\n",
    "            pickle.dump([hotshom, loaderhom, order], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname+'_model.pkl', 'rb') as file:\n",
    "            hotshom, loaderhom, order = pickle.load(file)\n",
    "            \n",
    "    if not os.path.isfile(fname+f'_evout_{nb_train}_{nb_test}.pkl'):       \n",
    "        _, loaderhom, out_train = hotshom.running(loaderhom, order, nb_digit = nb_train, LR=True)\n",
    "        _, loaderhom, out_test = hotshom.running(loaderhom, order, nb_digit = nb_test, LR=True)\n",
    "        with open(fname+f'_evout_{nb_train}_{nb_test}.pkl', 'wb') as file:\n",
    "            pickle.dump([out_train, out_test], file, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(fname+f'_evout_{nb_train}_{nb_test}.pkl', 'rb') as file:\n",
    "            out_train, out_test = pickle.load(file)\n",
    "    return out_train, out_test\n",
    "\n",
    "\n",
    "# ### Performingxlogistic regression\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "#\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import LogisticRegressionCV as LR\n",
    "# \n",
    "opts_LR = dict(max_iter=2000, # random_state=0,\n",
    "               n_jobs=-1, class_weight='balanced')\n",
    "#opts_LR['Cs'] = 5\n",
    "opts_LR['Cs'] = 32\n",
    "# TODO for a publication use 100 from 10^{-10} to 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tic():\n",
    "    global ttic\n",
    "    ttic = time.time()\n",
    "def toc():\n",
    "    print(f'Done in {time.time() - ttic:.3f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\") # -> torch.tensor([1.2, 3]).dtype = torch.float64\n",
    "criterion = torch.nn.NLLLoss(reduction=\"mean\") # loss divided by output size\n",
    "\n",
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    #torch.nn.Module -> Base class for all neural network modules\n",
    "    def __init__(self, N, n_classes, bias=True):\n",
    "        super(LogisticRegressionModel, self).__init__() \n",
    "        self.linear = torch.nn.Linear(N, n_classes, bias=bias)\n",
    "        self.nl = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, factors):\n",
    "        return self.nl(torch.squeeze(self.linear(factors),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "betas = (beta1, beta2)\n",
    "num_epochs = 2 ** 9 + 1\n",
    "batch_size = 256\n",
    "n_classes=10\n",
    "amsgrad = False # gives similar results\n",
    "amsgrad = True  # gives similar results\n",
    "\n",
    "def fit_data(factors, y, \n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,  # gamma=gamma,\n",
    "            num_epochs=num_epochs,\n",
    "            betas=betas,\n",
    "            verbose=False, **kwargs\n",
    "        ):\n",
    "\n",
    "    X, labels = torch.Tensor(factors[:, None]), torch.Tensor(y[:, None])\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(X, labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'device -> {device}')\n",
    "    \n",
    "    N_batch = factors.shape[0]\n",
    "    N = factors.shape[1]\n",
    "    n_classes = y.shape[1]\n",
    "    logistic_model = LogisticRegressionModel(N, n_classes)\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=betas, amsgrad=amsgrad\n",
    "    )\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        logistic_model.train()\n",
    "        losses = []\n",
    "        for X_, labels_ in loader:\n",
    "            X_, labels_ = X_.to(device), labels_.to(device)\n",
    "            outputs = logistic_model(X_)\n",
    "            target = torch.argmax(torch.squeeze(labels_,dim=1), 1)\n",
    "            loss = criterion(outputs, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if verbose and (epoch % (num_epochs // 32) == 0):\n",
    "            print(f\"Iteration: {epoch} - Loss: {np.mean(losses):.5f}\")\n",
    "            \n",
    "    logistic_model.eval()\n",
    "    X, labels = torch.Tensor(factors[:, None]), torch.Tensor(y[:, None])\n",
    "    X, labels = X.to(device), labels.to(device)\n",
    "    outputs = logistic_model(X)\n",
    "    target = torch.argmax(torch.squeeze(labels,dim=1), 1)\n",
    "    loss = criterion(outputs, target).item()\n",
    "    return logistic_model, loss\n",
    "\n",
    "def predict_data(factors, y, model,\n",
    "            batch_size=batch_size,  # gamma=gamma,\n",
    "            verbose=False, **kwargs\n",
    "        ):\n",
    "    batch_size = 1\n",
    "    X, labels = torch.Tensor(factors[:, None]), torch.Tensor(y[:, None])\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(X, labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'device -> {device}')\n",
    "\n",
    "    logistic_model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    acc = 0\n",
    "    for X_, labels_ in loader:\n",
    "        X_, labels_ = X_.to(device), labels_.to(device)\n",
    "        output = logistic_model(X_)\n",
    "        target = torch.argmax(torch.squeeze(labels_,dim=1), 1)\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "        pred = torch.argmax(torch.tensor(output), dim=1)\n",
    "        if pred.item()==target.item():\n",
    "            acc+=1\n",
    "    accuracy = acc/y.shape[0]\n",
    "    return losses, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../Data/nmnist_test.zip\n",
      "Extracting ../Data/nmnist_test.zip to ../Data/\n",
      "Done in 21.079 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "events_train, events_test = get_nmnist(nb_train, nb_test)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 8424 - Number of features: 2312\n",
      "Done in 1.940 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "X_train, y_train = gather_data(events_train, verbose=verbose)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device -> cuda\n",
      "Iteration: 0 - Loss: 0.59200\n",
      "Iteration: 16 - Loss: 0.00877\n",
      "Iteration: 32 - Loss: 0.00463\n",
      "Iteration: 48 - Loss: 0.00312\n",
      "Iteration: 64 - Loss: 0.00238\n",
      "Iteration: 80 - Loss: 0.00192\n",
      "Iteration: 96 - Loss: 0.00159\n",
      "Iteration: 112 - Loss: 0.00136\n",
      "Iteration: 128 - Loss: 0.00118\n",
      "Iteration: 144 - Loss: 0.00105\n",
      "Iteration: 160 - Loss: 0.00093\n",
      "Iteration: 176 - Loss: 0.00085\n",
      "Iteration: 192 - Loss: 0.00077\n",
      "Iteration: 208 - Loss: 0.00070\n",
      "Iteration: 224 - Loss: 0.00065\n",
      "Iteration: 240 - Loss: 0.00060\n",
      "Iteration: 256 - Loss: 0.00056\n",
      "Iteration: 272 - Loss: 0.00052\n",
      "Iteration: 288 - Loss: 0.00049\n",
      "Iteration: 304 - Loss: 0.00046\n",
      "Iteration: 320 - Loss: 0.00043\n",
      "Iteration: 336 - Loss: 0.00041\n",
      "Iteration: 352 - Loss: 0.00039\n",
      "Iteration: 368 - Loss: 0.00037\n",
      "Iteration: 384 - Loss: 0.00035\n",
      "Iteration: 400 - Loss: 0.00033\n",
      "Iteration: 416 - Loss: 0.00032\n",
      "Iteration: 432 - Loss: 0.00031\n",
      "Iteration: 448 - Loss: 0.00029\n",
      "Iteration: 464 - Loss: 0.00028\n",
      "Iteration: 480 - Loss: 0.00027\n",
      "Iteration: 496 - Loss: 0.00026\n",
      "Iteration: 512 - Loss: 0.00025\n",
      "Final loss = 0.0002514090867207038\n"
     ]
    }
   ],
   "source": [
    "N = X_train.shape[1]\n",
    "\n",
    "logistic_model = LogisticRegressionModel(N, n_classes)\n",
    "\n",
    "logistic_model, loss = fit_data(X_train, y_train, verbose=True)\n",
    "print(\"Final loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 8510 - Number of features: 2312\n",
      "device -> cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-a50d66b9e8e7>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.argmax(torch.tensor(output), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8336660537479885 0.6340775558166862\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = gather_data(events_test, verbose=verbose)\n",
    "loss, accuracy = predict_data(X_test, y_test, logistic_model)\n",
    "print(round(np.mean(loss),3), round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5dfad37eb0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(loss))\n",
    "plt.plot(range(X_test.shape[0]), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Records/EXP_03_NMNIST/2020-12-21_hots_nmnist_[4, 8, 16]_5_True_None_False_False\n",
      "Number of events: 7879 - Number of features: 18496\n",
      "device -> cuda\n",
      "Iteration: 0 - Loss: 0.22358\n",
      "Iteration: 16 - Loss: 0.00411\n",
      "Iteration: 32 - Loss: 0.00208\n",
      "Iteration: 48 - Loss: 0.00126\n",
      "Iteration: 64 - Loss: 0.00083\n",
      "Iteration: 80 - Loss: 0.00061\n",
      "Iteration: 96 - Loss: 0.00047\n",
      "Iteration: 112 - Loss: 0.00037\n",
      "Iteration: 128 - Loss: 0.00031\n",
      "Iteration: 144 - Loss: 0.00027\n",
      "Iteration: 160 - Loss: 0.00023\n",
      "Iteration: 176 - Loss: 0.00021\n",
      "Iteration: 192 - Loss: 0.00019\n",
      "Iteration: 208 - Loss: 0.00017\n",
      "Iteration: 224 - Loss: 0.00015\n",
      "Iteration: 240 - Loss: 0.00014\n",
      "Iteration: 256 - Loss: 0.00013\n",
      "Iteration: 272 - Loss: 0.00012\n",
      "Iteration: 288 - Loss: 0.00011\n",
      "Iteration: 304 - Loss: 0.00011\n",
      "Iteration: 320 - Loss: 0.00010\n",
      "Iteration: 336 - Loss: 0.00009\n",
      "Iteration: 352 - Loss: 0.00009\n",
      "Iteration: 368 - Loss: 0.00009\n",
      "Iteration: 384 - Loss: 0.00008\n",
      "Iteration: 400 - Loss: 0.00008\n",
      "Iteration: 416 - Loss: 0.00007\n",
      "Iteration: 432 - Loss: 0.00007\n",
      "Iteration: 448 - Loss: 0.00007\n",
      "Iteration: 464 - Loss: 0.00007\n",
      "Iteration: 480 - Loss: 0.00006\n",
      "Iteration: 496 - Loss: 0.00006\n",
      "Iteration: 512 - Loss: 0.00006\n",
      "Final loss = 5.925250879677615e-05\n"
     ]
    }
   ],
   "source": [
    "events_train_o, events_test_o = get_events(tau, krnlinit, nblay, nbclust, homeo, records_path, timestr, dataset, sigma, homeinv, jitter, nb_train, nb_test)\n",
    "X_train, y_train = gather_data(events_train_o, verbose=verbose)\n",
    "\n",
    "n_classes = y_train.shape[1]\n",
    "N = X_train.shape[1]\n",
    "\n",
    "logistic_model = LogisticRegressionModel(N, n_classes)\n",
    "\n",
    "logistic_model, loss = fit_data(X_train, y_train, verbose=True)\n",
    "print(\"Final loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 2765 - Number of features: 18496\n",
      "device -> cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-a50d66b9e8e7>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.argmax(torch.tensor(output), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.214 0.7\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = gather_data(events_test_o, verbose=verbose)\n",
    "loss, accuracy = predict_data(X_test, y_test, logistic_model)\n",
    "print(round(np.mean(loss),3), round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
